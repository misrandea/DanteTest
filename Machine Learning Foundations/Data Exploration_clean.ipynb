{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import sklearn\n",
    "import catboost\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. Data Exploration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# King County House Sales dataset from OpenML (includes Seattle)\n",
    "# this is an ARFF file, which is a text file with a specific format\n",
    "url = 'https://www.openml.org/data/download/22044765/dataset'\n",
    "cols = ['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "        'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "        'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'date_year', 'date_month', 'date_day']\n",
    "\n",
    "raw = pl.read_csv(url, new_columns=cols, skip_rows=31, has_header=False) # some rows are skipped due to dataset format\n",
    "\n",
    "# data summary\n",
    "#display(raw)\n",
    "raw.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "\n",
    "print(\"1) correlation\")\n",
    "display(raw\n",
    "        .to_pandas(use_pyarrow_extension_array=True)\n",
    "        .corr()\n",
    "        .style.background_gradient(cmap='RdBu', vmin=-1, vmax=1)\n",
    "       )\n",
    "\n",
    "print(\"2) scatter plot\")\n",
    "display(raw\n",
    "        .plot.scatter('sqft_living', 'price', alpha=0.1)\n",
    "       )\n",
    "\n",
    "print(\"3) plot the trend of price by date, grouped in zip code\")\n",
    "display(raw\n",
    "        .group_by('date_month', 'zipcode')\n",
    "        .agg(pl.col('price').mean())\n",
    "        .sort('date_month') #sort by date\n",
    "        .plot.line('date_month', 'price', by='zipcode', alpha=0.5)\n",
    "       )\n",
    "\n",
    "print(\"4) lat/long scatter plot\")\n",
    "# observed that prices are higher around the coast\n",
    "display(raw\n",
    "        #.filter(pl.col('price') > 1_000_000) # to display luxurious houses better, filter out house prices below $1 Mil. \n",
    "        .sort('price')\n",
    "        .plot.scatter(x='long', y='lat', alpha=0.5, c='price', s=1) # this display prices on a map\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2. Data Preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn pipelines\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer #ColumnTransformer is a tool that allows us to run certain steps just on specific columns, not on everything in there\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #StandardScaler standardizes the data, meaning it gives each column a mean value of zero and a standard deviation of one; OneHotEncoder is a mechanism for taking categorical data, because most machine learning algorithms don't work with text data or categorical data, and it encodes that into numeric values\n",
    "from sklearn.impute import SimpleImputer #SimpleImputer that fills in missing values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer #FunctionTransformer is a class from Scikit-Learn that allows converting a function into a transformer to stick into a pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='polars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 handle numerical variables\n",
    "#print(tweak_housing(raw).select(cs.numeric()).columns) # identify numerical columns in the dataset\n",
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "                    'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \n",
    "                    'lat', 'long', 'sqft_living15', 'sqft_lot15', 'zip_mean']  # note that zip_mean will be added in step 3.0 as the average price of a zipcode\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())]) # define numerical transformer\n",
    "\n",
    "# 1.2 handle categorical variables\n",
    "categorical_features = ['zipcode']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore',\n",
    "                                        sparse_output=False, max_categories=10) # allow only 10 categorical vars to be created instead of high-dimentional zip codes\n",
    "\n",
    "\n",
    "# *1.3 Column Transformer: apply numerical transformation to number columns and categorical transformer to categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Tweak function: define a function to tweak housing data by condensing date information and adjusting renovated years\n",
    "def tweak_housing(df):\n",
    "    return (df\n",
    "            .with_columns(zipcode=pl.col('zipcode').cast(pl.String).cast(pl.Categorical),\n",
    "                          date=pl.date(pl.col('date_year'), pl.col('date_month'), pl.col('date_day')),\n",
    "                          yr_renovated=pl.col('yr_renovated').replace(0, None),\n",
    "                          )\n",
    "            .select(['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "                     'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', \n",
    "                     'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', \n",
    "                     'sqft_lot15', 'date',  #'date_year', 'date_month', 'date_day', \n",
    "                     ])\n",
    "    )\n",
    "#tweak_housing(raw)\n",
    "\n",
    "# *2.2 Treak Transformer: Treak function as a transformer\n",
    "tweak_transformer = FunctionTransformer(tweak_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *3.0 Custom Transformer\n",
    "class ZipAvgPriceAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        # assume X is a polars dataframe\n",
    "        self.zip_avg_price = (X\n",
    "                              .group_by('zipcode')\n",
    "                              .agg(zip_mean=pl.col('price').mean()) # map the zip code to the average price of that zip code\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.join(self.zip_avg_price, on='zipcode') # add zip average price to columns of X\n",
    "\n",
    "#zip_adder = ZipAvgPriceAdder()\n",
    "#zip_adder.fit_transform(raw.select(['zipcode', 'price'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0 Make the Pipeline!\n",
    "# Append classifier to preprocessing pipeline. Now we have a full prediction pipeline.\n",
    "pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ])\n",
    "\n",
    "X = raw #.drop('price')\n",
    "y = raw.select('price') # Note sklearn wants a Polars dataframe for y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# outputs:\n",
    "display(pipe)\n",
    "display(pipe.fit_transform(raw, raw.select('price'))) # Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
